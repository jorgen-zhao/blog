(window.webpackJsonp=window.webpackJsonp||[]).push([[80],{426:function(t,a,s){"use strict";s.r(a);var e=s(14),n=Object(e.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h2",{attrs:{id:"flink-架构"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#flink-架构"}},[t._v("#")]),t._v(" flink 架构")]),t._v(" "),a("p",[t._v("Flink采取master - worker的结构架构，主要包括两个组件")]),t._v(" "),a("ol",[a("li",[t._v("Master: Flink作业的主进程，它主要起协调管理的作用")]),t._v(" "),a("li",[t._v("TaskManager: 执行计算任务的进程，拥有CPU，内存等资源。Flink需要将计算任务发往多个taskmanger上并行执行任务。")])]),t._v(" "),a("h3",{attrs:{id:"flink作业提交的过程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#flink作业提交的过程"}},[t._v("#")]),t._v(" Flink作业提交的过程")]),t._v(" "),a("p",[a("img",{attrs:{src:"/tool/05/201/job-submmit.jpg",alt:"standalone模式下，作业提交的流程图"}})]),t._v(" "),a("p",[t._v("在一个作业提交前，master与taskmanager需要首先被启动。单机版flink直接使用"),a("code",[t._v("bin/start-cluser")]),t._v("命令进行启动，taskmanger启动后向Resource manger注册。这个流程在用户提交jar包前执行。")]),t._v(" "),a("ol",[a("li",[t._v("用户通过SDK编写好的程序，通过client进行提交。现在通常使用Java语言编写，构建逻辑视角数据流图。代码和相关配置文件进行打包编译构建，通过客户端提交到dispatcher，形成一个作业Job.")]),t._v(" "),a("li",[t._v("Dispatcher收到这个作业之后，会启动Jobmanager，负责协调本次的工作。")]),t._v(" "),a("li",[t._v("Jobmanger向Resource manager申请本次作业所需要的资源。")]),t._v(" "),a("li",[t._v("在整个flink刚启动时，taskmanger已经向resource manger注册，此时，闲置的taskmanager将会反馈给jobmanager。")]),t._v(" "),a("li",[t._v("jobmanager将用户作业中的逻辑视图转换为物理执行图，将计算任务分发给多个taskmager。")])]),t._v(" "),a("p",[t._v("一个Flink job开始执行！！！")]),t._v(" "),a("h3",{attrs:{id:"graph"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#graph"}},[t._v("#")]),t._v(" graph")]),t._v(" "),a("div",{staticClass:"language-Java line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("public")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("static")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("void")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("main")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("throws")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Exception")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 检查输入")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ParameterTool")]),t._v(" params "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ParameterTool")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("fromArgs")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("args"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// set up the execution environment")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("final")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("StreamExecutionEnvironment")]),t._v(" env "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("StreamExecutionEnvironment")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getExecutionEnvironment")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// get input data")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DataStream")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" text "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n      env"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("socketTextStream")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("params"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("get")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"hostname"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" params"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("getInt")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"port"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token char"}},[t._v("'\\n'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n  "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("DataStream")]),a("span",{pre:!0,attrs:{class:"token generics"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tuple2")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("String")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Integer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v(" counts "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("\n      "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// split up the lines in pairs (2-tuples) containing: (word,1)")]),t._v("\n      text"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("flatMap")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Tokenizer")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('// group by the tuple field "0" and sum up tuple field "1"')]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("keyBy")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n          "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("sum")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  counts"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  \n  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// execute program")]),t._v("\n  env"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("execute")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"WordCount from SocketTextStream Example"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br"),a("span",{staticClass:"line-number"},[t._v("7")]),a("br"),a("span",{staticClass:"line-number"},[t._v("8")]),a("br"),a("span",{staticClass:"line-number"},[t._v("9")]),a("br"),a("span",{staticClass:"line-number"},[t._v("10")]),a("br"),a("span",{staticClass:"line-number"},[t._v("11")]),a("br"),a("span",{staticClass:"line-number"},[t._v("12")]),a("br"),a("span",{staticClass:"line-number"},[t._v("13")]),a("br"),a("span",{staticClass:"line-number"},[t._v("14")]),a("br"),a("span",{staticClass:"line-number"},[t._v("15")]),a("br"),a("span",{staticClass:"line-number"},[t._v("16")]),a("br"),a("span",{staticClass:"line-number"},[t._v("17")]),a("br"),a("span",{staticClass:"line-number"},[t._v("18")]),a("br"),a("span",{staticClass:"line-number"},[t._v("19")]),a("br"),a("span",{staticClass:"line-number"},[t._v("20")]),a("br"),a("span",{staticClass:"line-number"},[t._v("21")]),a("br"),a("span",{staticClass:"line-number"},[t._v("22")]),a("br"),a("span",{staticClass:"line-number"},[t._v("23")]),a("br")])]),a("p",[a("img",{attrs:{src:"/tool/05/201/graph.png",alt:"standalone模式下，作业提交的流程图"}})]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("图")]),t._v(" "),a("th",[t._v("描述")]),t._v(" "),a("th",[t._v("细节")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("StreamGraph")]),t._v(" "),a("td",[t._v("根据用户通过 Stream API 编写的代码生成的最初的图。用来表示程序的拓扑结构。")]),t._v(" "),a("td",[a("code",[t._v("StreamNode")]),t._v("：用来代表 operator 的类，并具有所有相关的属性，如并发度、入边和出边等。 "),a("br"),t._v(" "),a("code",[t._v("StreamEdge")]),t._v("：表示连接两个StreamNode的边。")])]),t._v(" "),a("tr",[a("td",[t._v("JobGraph")]),t._v(" "),a("td",[t._v("StreamGraph经过优化后生成了 JobGraph，提交给 JobManager 的数据结构。主要的优化为，将多个符合条件的节点 chain 在一起作为一个节点，这样可以减少数据在节点之间流动所需要的序列化/反序列化/传输消耗。")]),t._v(" "),a("td",[a("code",[t._v("JobVertex")]),t._v("：经过优化后符合条件的多个"),a("code",[t._v("StreamNode")]),t._v("可能会chain在一起生成一个"),a("code",[t._v("JobVertex")]),t._v("，即一个"),a("code",[t._v("JobVertex")]),t._v("包含一个或多个operator，"),a("code",[t._v("JobVertex")]),t._v("的输入是"),a("code",[t._v("JobEdge")]),t._v("，输出是"),a("code",[t._v("IntermediateDataSet")]),t._v("。 "),a("br"),t._v(" "),a("code",[t._v("IntermediateDataSet")]),t._v("：表示"),a("code",[t._v("JobVertex")]),t._v("的输出，即经过operator处理产生的数据集。producer是"),a("code",[t._v("JobVertex")]),t._v("，consumer是"),a("code",[t._v("JobEdge")]),t._v("。 "),a("br"),t._v(" "),a("code",[t._v("JobEdge")]),t._v("：代表了job graph中的一条数据传输通道。source 是 "),a("code",[t._v("IntermediateDataSet")]),t._v("，target 是 JobVertex。即数据通过JobEdge由IntermediateDataSet传递给目标JobVertex。")])]),t._v(" "),a("tr",[a("td",[t._v("ExecutionGraph")]),t._v(" "),a("td",[t._v("JobManager 根据 JobGraph 生成ExecutionGraph。ExecutionGraph是JobGraph的并行化版本，是调度层最核心的数据结构。")]),t._v(" "),a("td",[a("code",[t._v("ExecutionJobVertex")]),t._v("：和JobGraph中的JobVertex一一对应。每一个ExecutionJobVertex都有和并发度一样多的 ExecutionVertex。"),a("br"),t._v(" "),a("code",[t._v("ExecutionVertex")]),t._v("：表示ExecutionJobVertex的其中一个并发子任务，输入是ExecutionEdge，输出是IntermediateResultPartition。 "),a("br"),t._v(" "),a("code",[t._v("IntermediateResult")]),t._v("：和JobGraph中的IntermediateDataSet一一对应。一个IntermediateResult包含多个IntermediateResultPartition，其个数等于该operator的并发度。 "),a("br"),t._v(" "),a("code",[t._v("IntermediateResultPartition")]),t._v("：表示ExecutionVertex的一个输出分区，producer是ExecutionVertex，consumer是若干个ExecutionEdge。"),a("br"),t._v(" "),a("code",[t._v("ExecutionEdge")]),t._v("：表示ExecutionVertex的输入，source是IntermediateResultPartition，target是ExecutionVertex。source和target都只能是一个。 "),a("br"),a("code",[t._v("Execution")]),t._v("：是执行一个 ExecutionVertex 的一次尝试。当发生故障或者数据需要重算的情况下 ExecutionVertex 可能会有多个 ExecutionAttemptID。一个 Execution 通过 ExecutionAttemptID 来唯一标识。JM和TM之间关于 task 的部署和 task status 的更新都是通过 ExecutionAttemptID 来确定消息接受者。")])]),t._v(" "),a("tr",[a("td",[t._v("物理执行图")]),t._v(" "),a("td",[t._v("JobManager 根据 ExecutionGraph 对 Job 进行调度后，在各个TaskManager 上部署 Task 后形成的“图”，并不是一个具体的数据结构。")]),t._v(" "),a("td",[a("code",[t._v("Task")]),t._v("：Execution被调度后在分配的 TaskManager 中启动对应的 Task。Task 包裹了具有用户执行逻辑的 operator。 "),a("br"),a("code",[t._v("ResultPartition")]),t._v("：代表由一个Task的生成的数据，和ExecutionGraph中的IntermediateResultPartition一一对应。 "),a("br"),a("code",[t._v("ResultSubpartition")]),t._v("：是ResultPartition的一个子分区。每个ResultPartition包含多个ResultSubpartition，其数目要由下游消费 Task 数和 DistributionPattern 来决定。 "),a("br"),a("code",[t._v("InputGate")]),t._v("：代表Task的输入封装，和JobGraph中JobEdge一一对应。每个InputGate消费了一个或多个的ResultPartition。 "),a("br"),a("code",[t._v("InputChannel")]),t._v("：每个InputGate会包含一个以上的InputChannel，和ExecutionGraph中的ExecutionEdge一一对应，也和ResultSubpartition一对一地相连，即一个InputChannel接收一个ResultSubpartition的输出。")])])])]),t._v(" "),a("h3",{attrs:{id:"任务执行-资源划分"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#任务执行-资源划分"}},[t._v("#")]),t._v(" 任务执行 资源划分")]),t._v(" "),a("p",[t._v("算子子任务是Flink物理执行的基本单元，算子子任务之间是相互独立的，某个算子子任务有自己的线程，不同算子子任务可能分布在不同的机器节点上。算子子任务、分区、实例都是指对算子的并行切分")]),t._v(" "),a("p",[t._v("数据交换策略")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("策略")]),t._v(" "),a("th",[t._v("描述")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("前向传播(Forward)")]),t._v(" "),a("td",[t._v("前一个算子子任务直接传递数据给后一个算子子任务，避免了跨分区交换和相关开销。")])]),t._v(" "),a("tr",[a("td",[t._v("按Key分组(Key-Based)")]),t._v(" "),a("td",[t._v("数据以(Key, Value)形式存在，按Key进行分组，相同Key的数据分到同一组，发送到同一分区。在WordCount程序中，keyBy将单词作为Key，将相同单词发送到同一分区，便于后续算子的聚合统计。")])]),t._v(" "),a("tr",[a("td",[t._v("广播(broadcase)")]),t._v(" "),a("td",[t._v("将某份数据广播到所有分区，涉及全局数据的拷贝，因此资源消耗较大。")])]),t._v(" "),a("tr",[a("td",[t._v("随机策略(Random)")]),t._v(" "),a("td",[t._v("将所有数据均匀地随机发送到多个分区，确保数据平均分布到不同分区。通常用于防止数据倾斜到某些分区，导致部分分区数据稀疏，另一些分区数据拥挤。")])])])]),t._v(" "),a("h2",{attrs:{id:"任务槽位与计算资源"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#任务槽位与计算资源"}},[t._v("#")]),t._v(" 任务槽位与计算资源")]),t._v(" "),a("h3",{attrs:{id:"task-slot"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#task-slot"}},[t._v("#")]),t._v(" Task Slot")]),t._v(" "),a("ol",[a("li",[t._v("TaskManager 是一个JVM进程，taskManager可以管理一至多个Task")]),t._v(" "),a("li",[t._v("每个Task是一个线程，占用一个slot")]),t._v(" "),a("li",[t._v("每个slot是taskManager资源的子集")])]),t._v(" "),a("h3",{attrs:{id:"槽位共享"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#槽位共享"}},[t._v("#")]),t._v(" 槽位共享")]),t._v(" "),a("p",[t._v("Slot Sharing，进一步优化数据传输开销，充分利用计算资源。\nFlink的一个槽位可能运行"),a("strong",[t._v("一个算子任务")]),t._v("；也可以是"),a("strong",[t._v("被链接的多个子任务组成的Task")]),t._v("，或者是"),a("strong",[t._v("共享槽位的多个Task")]),t._v("。")]),t._v(" "),a("h2",{attrs:{id:"time"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#time"}},[t._v("#")]),t._v(" time")]),t._v(" "),a("h3",{attrs:{id:"event-time"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#event-time"}},[t._v("#")]),t._v(" Event Time")]),t._v(" "),a("p",[t._v("Event Time指的是数据流中每个元素或者每个事件自带的时间属性，一般是事件发生的时间。由于事件从发生到进入Flink时间算子之间有很多环节，一个较早发生的事件因为延迟可能较晚到达，因此使用Event Time意味着事件到达有可能是乱序的。")]),t._v(" "),a("p",[t._v("使用Event Time时，最理想的情况下，我们可以一直等待所有的事件到达后再进行时间窗口的处理。假设一个时间窗口内的所有数据都已经到达，基于Event Time的流处理会得到正确且一致的结果。无论我们是将同一个程序部署在不同的计算环境，还是在相同的环境下多次计算同一份数据，都能够得到同样的计算结果。我们根本不同担心乱序到达的问题。")]),t._v(" "),a("p",[t._v("但这只是理想情况，现实中无法实现，因为我们既不知道究竟要等多长时间才能确认所有事件都已经到达，更不可能无限地一直等待下去。在实际应用中，当涉及到对事件按照时间窗口进行统计时，Flink会将窗口内的事件缓存下来，直到接收到一个Watermark，Watermark假设不会有更晚数据的到达。Watermark意味着在一个时间窗口下，Flink会等待一个有限的时间，这在一定程度上降低了计算结果的绝对准确性，而且增加了系统的延迟。比起其他几种时间语义，使用Event Time的好处是某个事件的时间是确定的，这样能够保证计算结果在一定程度上的可预测性。")]),t._v(" "),a("p",[t._v("一个基于Event Time的Flink程序中必须定义：一、每条数据的Event Time时间戳作为Event Tme，二、如何生成Watermark。我们可以使用数据自带的时间作为Event Time，也可以在数据到达Flink后人为给Event Time赋值。")]),t._v(" "),a("p",[t._v("总之，使用Event Time的优势是结果的可预测性，缺点是缓存较大，增加了延迟，且调试和定位问题更复杂。")]),t._v(" "),a("h3",{attrs:{id:"processing-time"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#processing-time"}},[t._v("#")]),t._v(" Processing Time")]),t._v(" "),a("p",[t._v("对于某个算子来说，Processing Time指算子使用当前机器的系统时钟时间。在Processing Time的时间窗口场景下，无论事件什么时候发生，只要该事件在某个时间段到达了某个算子，就会被归结到该窗口下，不需要Watermark机制。对于一个程序，在同一个计算环境来说，每个算子都有一定的耗时，同一个事件的Processing Time，第n个算子和第n+1个算子不同。如果一个程序在不同的集群和环境下执行，限于软硬件因素，不同环境下前序算子处理速度不同，对于下游算子来说，事件的Processing Time也会不同，不同环境下时间窗口的计算结果会发生变化。因此，Processing Time在时间窗口下的计算会有不确定性。")]),t._v(" "),a("p",[t._v("Processing Time只依赖当前执行机器的系统时钟，不需要依赖Watermark，无需缓存。Processing Time是实现起来非常简单，也是延迟最小的一种时间语义。")]),t._v(" "),a("h3",{attrs:{id:"ingestion-time"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#ingestion-time"}},[t._v("#")]),t._v(" Ingestion Time")]),t._v(" "),a("p",[t._v("Ingestion Time是事件到达Flink Source的时间。从Source到下游各个算子中间可能有很多计算环节，任何一个算子的处理速度快慢可能影响到下游算子的Processing Time。而Ingestion Time定义的是数据流最早进入Flink的时间，因此不会被算子处理速度影响。")]),t._v(" "),a("p",[t._v("Ingestion Time通常是Event Time和Processing Time之间的一个折中方案。比起Event Time，Ingestion Time可以不需要设置复杂的Watermark，因此也不需要太多缓存，延迟较低。比起Processing Time，Ingestion Time的时间是Source赋值的，一个事件在整个处理过程从头至尾都使用这个时间，而且后续算子不受前序算子处理速度的影响，计算结果相对准确一些，但计算成本比Processing Time稍高。")]),t._v(" "),a("h2",{attrs:{id:"设置时间语义"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#设置时间语义"}},[t._v("#")]),t._v(" 设置时间语义")]),t._v(" "),a("h3",{attrs:{id:"watermark"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#watermark"}},[t._v("#")]),t._v(" watermark")]),t._v(" "),a("h3",{attrs:{id:"window"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#window"}},[t._v("#")]),t._v(" window")]),t._v(" "),a("h2",{attrs:{id:"参考"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#参考"}},[t._v("#")]),t._v(" 参考")]),t._v(" "),a("ol",[a("li",[t._v("http://wuchong.me/categories/Flink/")]),t._v(" "),a("li",[t._v("https://lulaoshi.info/flink/chapter-system-design/dataflow.html")])])])}),[],!1,null,null,null);a.default=n.exports}}]);