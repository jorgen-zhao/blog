---
title: Androidåº”ç”¨AIé›†æˆä¸æœºå™¨å­¦ä¹ å®æˆ˜æŒ‡å—-æ‰“é€ æ™ºèƒ½åº”ç”¨çš„æ ¸å¿ƒæŠ€å·§
date: 2026-02-06
tags: [Android AI, æœºå™¨å­¦ä¹ , æ™ºèƒ½åº”ç”¨]
---

## å‰è¨€

éšç€äººå·¥æ™ºèƒ½æŠ€æœ¯çš„é£é€Ÿå‘å±•ï¼ŒAIå·²ç»æ·±å…¥åˆ°æˆ‘ä»¬æ—¥å¸¸ç”Ÿæ´»çš„æ–¹æ–¹é¢é¢ã€‚ä½œä¸ºç§»åŠ¨å¼€å‘è€…çš„æˆ‘ä»¬ï¼Œå¦‚ä½•å°†AIæŠ€æœ¯èå…¥Androidåº”ç”¨ï¼Œä¸ºç”¨æˆ·æä¾›æ›´æ™ºèƒ½ã€æ›´ä¸ªæ€§åŒ–çš„ä½“éªŒï¼Œå·²æˆä¸ºä¸€é¡¹å¿…å¤‡æŠ€èƒ½ã€‚ğŸ¤–

æœ¬æ–‡å°†å…¨é¢ä»‹ç»åœ¨Androidåº”ç”¨ä¸­é›†æˆAIå’Œæœºå™¨å­¦ä¹ æŠ€æœ¯çš„å„ç§æ–¹æ³•ï¼Œä»åŸºç¡€çš„ML Kitåˆ°è‡ªå®šä¹‰æ¨¡å‹è®­ç»ƒï¼Œå¸®åŠ©ä½ æ‰“é€ çœŸæ­£æ™ºèƒ½çš„Androidåº”ç”¨ã€‚

## Android AIå¼€å‘æ¦‚è¿°

Androidå¹³å°ä¸ºå¼€å‘è€…æä¾›äº†ä¸°å¯Œçš„AIå’Œæœºå™¨å­¦ä¹ å·¥å…·å’Œæ¡†æ¶ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿè½»æ¾åœ°å°†æ™ºèƒ½åŠŸèƒ½é›†æˆåˆ°åº”ç”¨ä¸­ã€‚è¿™äº›å·¥å…·å¤§è‡´å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å‡ ç±»ï¼š

1. **Google ML Kit** - æä¾›é¢„è®­ç»ƒçš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæ”¯æŒå¤šç§å¸¸è§AIä»»åŠ¡
2. **TensorFlow Lite** - ç”¨äºåœ¨ç§»åŠ¨è®¾å¤‡ä¸Šè¿è¡ŒTensorFlowæ¨¡å‹
3. **Android NN API** - æä¾›å¯¹è®¾å¤‡ç¥ç»ç½‘ç»œç¡¬ä»¶åŠ é€Ÿçš„è®¿é—®
4. **CameraX** - ç®€åŒ–ç›¸æœºåŠŸèƒ½çš„ä½¿ç”¨ï¼Œå¸¸ç”¨äºè®¡ç®—æœºè§†è§‰åº”ç”¨
5. **è‡ªå®šä¹‰æ¨¡å‹** - ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œé›†æˆåˆ°Androidåº”ç”¨ä¸­

## ä½¿ç”¨ML Kitå®ç°å¸¸ç”¨AIåŠŸèƒ½

ML Kitæ˜¯Googleæä¾›çš„ç§»åŠ¨ç«¯æœºå™¨å­¦ä¹ å·¥å…·åŒ…ï¼Œå®ƒæä¾›äº†å¤šç§é¢„è®­ç»ƒæ¨¡å‹ï¼Œå¯ä»¥å¿«é€Ÿå®ç°å„ç§AIåŠŸèƒ½ã€‚

### æ–‡æœ¬è¯†åˆ«

ML Kitçš„æ–‡æœ¬è¯†åˆ«åŠŸèƒ½å¯ä»¥è¯†åˆ«å›¾åƒä¸­çš„æ–‡æœ¬ï¼Œæ”¯æŒå¤šç§è¯­è¨€ã€‚

```kotlin
// åˆ›å»ºæ–‡æœ¬è¯†åˆ«å™¨
val textRecognizer = TextRecognition.getClient(TextRecognitionOptions.Builder().build())

// ä»Bitmapåˆ›å»ºè¾“å…¥å›¾åƒ
val image = InputImage.fromBitmap(bitmap, 0)

// è¿è¡Œæ–‡æœ¬è¯†åˆ«
textRecognizer.process(image)
    .addOnSuccessListener { text ->
        // è¯†åˆ«æˆåŠŸ
        val resultText = text.text
        // å¤„ç†è¯†åˆ«ç»“æœ
    }
    .addOnFailureListener { e ->
        // è¯†åˆ«å¤±è´¥
        e.printStackTrace()
    }
```

### é¢éƒ¨æ£€æµ‹

ML Kitçš„é¢éƒ¨æ£€æµ‹åŠŸèƒ½å¯ä»¥æ£€æµ‹å›¾åƒä¸­çš„äººè„¸ï¼Œå¹¶è·å–é¢éƒ¨ç‰¹å¾ä¿¡æ¯ã€‚

```kotlin
// åˆ›å»ºé¢éƒ¨æ£€æµ‹å™¨
val faceDetector = FaceDetection.getClient(options)

// ä»Bitmapåˆ›å»ºè¾“å…¥å›¾åƒ
val image = InputImage.fromBitmap(bitmap, 0)

// è¿è¡Œé¢éƒ¨æ£€æµ‹
faceDetector.process(image)
    .addOnSuccessListener { faces ->
        // æ£€æµ‹æˆåŠŸ
        for (face in faces) {
            val boundingBox = face.boundingBox
            val landmarks = face.landmarks
            // å¤„ç†æ£€æµ‹åˆ°çš„äººè„¸
        }
    }
    .addOnFailureListener { e ->
        // æ£€æµ‹å¤±è´¥
        e.printStackTrace()
    }
```

### æ ‡ç­¾è¯†åˆ«

ML Kitçš„æ ‡ç­¾è¯†åˆ«åŠŸèƒ½å¯ä»¥è¯†åˆ«å›¾åƒä¸­çš„å¯¹è±¡å’Œåœºæ™¯ã€‚

```kotlin
// åˆ›å»ºå›¾åƒæ ‡ç­¾è¯†åˆ«å™¨
val labeler = ImageLabeling.getClient(ImageLabelerOptions.Builder().build())

// ä»Bitmapåˆ›å»ºè¾“å…¥å›¾åƒ
val image = InputImage.fromBitmap(bitmap, 0)

// è¿è¡Œæ ‡ç­¾è¯†åˆ«
labeler.process(image)
    .addOnSuccessListener { labels ->
        // è¯†åˆ«æˆåŠŸ
        for (label in labels) {
            val text = label.text
            val confidence = label.confidence
            // å¤„ç†è¯†åˆ«ç»“æœ
        }
    }
    .addOnFailureListener { e ->
        // è¯†åˆ«å¤±è´¥
        e.printStackTrace()
    }
```

## ä½¿ç”¨TensorFlow Liteå®ç°è‡ªå®šä¹‰æ¨¡å‹

å½“ML Kitæä¾›çš„é¢„è®­ç»ƒæ¨¡å‹æ— æ³•æ»¡è¶³éœ€æ±‚æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨TensorFlow Liteæ¥è¿è¡Œè‡ªå®šä¹‰è®­ç»ƒçš„æ¨¡å‹ã€‚

### æ·»åŠ TensorFlow Liteä¾èµ–

åœ¨appæ¨¡å—çš„build.gradleæ–‡ä»¶ä¸­æ·»åŠ TensorFlow Liteä¾èµ–ï¼š

```gradle
dependencies {
    implementation 'org.tensorflow:tensorflow-lite:2.4.0'
    // å¦‚æœä½¿ç”¨GPUåŠ é€Ÿ
    implementation 'org.tensorflow:tensorflow-lite-gpu:2.4.0'
    // å¦‚æœæ”¯æŒæ¨¡å‹é‡åŒ–
    implementation 'org.tensorflow:tensorflow-lite-support:0.4.2'
}
```

### åŠ è½½å’Œè¿è¡ŒTensorFlow Liteæ¨¡å‹

```kotlin
// åŠ è½½TensorFlow Liteæ¨¡å‹
val model = Model.newInstance(context)

// å‡†å¤‡è¾“å…¥æ•°æ®
val inputFeature0 = TensorBuffer.createFixedSize(intArrayOf(1, 224, 224, 3), DataType.FLOAT32)
inputFeature0.loadBuffer(...)

// è¿è¡Œæ¨ç†
val outputs = model.process(inputFeature0)
val outputFeature0 = outputs.outputFeature0AsTensorBuffer

// è·å–ç»“æœ
val result = outputFeature0.floatArray

// å…³é—­æ¨¡å‹
model.close()
```

### ä½¿ç”¨GPUåŠ é€Ÿæ¨ç†

ä¸ºäº†æé«˜æ¨ç†é€Ÿåº¦ï¼Œå¯ä»¥ä½¿ç”¨GPUåŠ é€Ÿï¼š

```kotlin
val options = Interpreter.Options()
options.addDelegate(GpuDelegate())

val interpreter = Interpreter(loadModelFile(), options)
```

## é›†æˆè®¡ç®—æœºè§†è§‰åŠŸèƒ½

è®¡ç®—æœºè§†è§‰æ˜¯AIåœ¨ç§»åŠ¨åº”ç”¨ä¸­æœ€å¸¸è§çš„åº”ç”¨åœºæ™¯ä¹‹ä¸€ã€‚ä¸‹é¢ä»‹ç»å¦‚ä½•ä½¿ç”¨Androidå·¥å…·å®ç°å¸¸è§çš„è®¡ç®—æœºè§†è§‰åŠŸèƒ½ã€‚

### å®æ—¶å›¾åƒå¤„ç†

ä½¿ç”¨CameraXå’ŒOpenGL ESå®ç°å®æ—¶å›¾åƒå¤„ç†ï¼š

```kotlin
// é…ç½®CameraX
val cameraProviderFuture = ProcessCameraProvider.getInstance(context)
cameraProviderFuture.addListener({
    val cameraProvider = cameraProviderFuture.get()
    
    // è®¾ç½®é¢„è§ˆåˆ†æç”¨ä¾‹
    val imageAnalysis = ImageAnalysis.Builder()
        .setBackpressureStrategy(ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)
        .build()
    
    imageAnalysis.setAnalyzer(ContextCompat.getMainExecutor(context)) { imageProxy ->
        // å¤„ç†å›¾åƒ
        processImage(imageProxy)
        imageProxy.close()
    }
    
    // ç»‘å®šç›¸æœº
    val cameraSelector = CameraSelector.DEFAULT_BACK_CAMERA
    cameraProvider.bindToLifecycle(lifecycleOwner, cameraSelector, imageAnalysis)
}, ContextCompat.getMainExecutor(context))

// å›¾åƒå¤„ç†å‡½æ•°
private fun processImage(imageProxy: ImageProxy) {
    val image = imageProxy.image ?: return
    
    // å°†å›¾åƒè½¬æ¢ä¸ºBitmap
    val bitmap = toBitmap(image)
    
    // åº”ç”¨å›¾åƒå¤„ç†ç®—æ³•
    val processedBitmap = applyImageProcessing(bitmap)
    
    // æ˜¾ç¤ºå¤„ç†åçš„å›¾åƒ
    runOnUiThread {
        imageView.setImageBitmap(processedBitmap)
    }
}
```

### ç›®æ ‡æ£€æµ‹ä¸è·Ÿè¸ª

ä½¿ç”¨TensorFlow Liteå®ç°ç›®æ ‡æ£€æµ‹ï¼š

```kotlin
class ObjectDetectionModel(context: Context) {
    private val interpreter: Interpreter
    private val inputImageSize: Int = 300 // æ¨¡å‹è¾“å…¥å›¾åƒå¤§å°
    
    init {
        // åŠ è½½æ¨¡å‹
        val model = FileUtil.loadMappedFile(context, "detect.tflite")
        val options = Interpreter.Options()
        interpreter = Interpreter(model, options)
    }
    
    fun detectObjects(bitmap: Bitmap): List<DetectionResult> {
        // é¢„å¤„ç†å›¾åƒ
        val resizedBitmap = Bitmap.createScaledBitmap(bitmap, inputImageSize, inputImageSize, true)
        val inputBuffer = convertBitmapToByteBuffer(resizedBitmap)
        
        // è¿è¡Œæ¨ç†
        val output = Array(1) { Array(10) { FloatArray(7) } }
        interpreter.run(inputBuffer, output)
        
        // è§£æç»“æœ
        return parseDetectionResults(output[0])
    }
    
    private fun convertBitmapToByteBuffer(bitmap: Bitmap): ByteBuffer {
        val byteBuffer = ByteBuffer.allocateDirect(4 * inputImageSize * inputImageSize * 3)
        byteBuffer.order(ByteOrder.nativeOrder())
        
        val intValues = IntArray(inputImageSize * inputImageSize)
        bitmap.getPixels(intValues, 0, bitmap.width, 0, 0, bitmap.width, bitmap.height)
        
        var pixel = 0
        for (i in 0 until inputImageSize) {
            for (j in 0 until inputImageSize) {
                val `val` = intValues[pixel++]
                byteBuffer.putFloat((`val` shr 16 and 0xFF) / 255.0f)
                byteBuffer.putFloat((`val` shr 8 and 0xFF) / 255.0f)
                byteBuffer.putFloat((`val` and 0xFF) / 255.0f)
            }
        }
        
        return byteBuffer
    }
    
    private fun parseDetectionResults(output: Array<FloatArray>): List<DetectionResult> {
        val results = mutableListOf<DetectionResult>()
        
        // éå†æ‰€æœ‰æ£€æµ‹ç»“æœ
        for (i in output.indices) {
            val confidence = output[i][2]
            if (confidence > 0.5) { // ç½®ä¿¡åº¦é˜ˆå€¼
                val classId = output[i][1].toInt()
                val left = output[i][3] * bitmap.width
                val top = output[i][4] * bitmap.height
                val right = output[i][5] * bitmap.width
                val bottom = output[i][6] * bitmap.height
                
                results.add(DetectionResult(classId, confidence, left, top, right, bottom))
            }
        }
        
        return results
    }
}
```

## å®ç°è‡ªç„¶è¯­è¨€å¤„ç†åŠŸèƒ½

è‡ªç„¶è¯­è¨€å¤„ç†(NLP)æ˜¯AIçš„å¦ä¸€ä¸ªé‡è¦åº”ç”¨é¢†åŸŸï¼ŒAndroidåº”ç”¨ä¸­å¸¸è§çš„NLPåŠŸèƒ½åŒ…æ‹¬æ–‡æœ¬åˆ†æã€æƒ…æ„Ÿåˆ†æã€èŠå¤©æœºå™¨äººç­‰ã€‚

### ä½¿ç”¨ML Kitè¿›è¡Œè¯­è¨€è¯†åˆ«

```kotlin
// åˆ›å»ºè¯­è¨€è¯†åˆ«å™¨
val languageIdentifier = LanguageIdentification.getClient()

// è¯†åˆ«æ–‡æœ¬è¯­è¨€
languageIdentifier.identifyLanguage("Hello, world!")
    .addOnSuccessListener { languageCode ->
        // è¯†åˆ«æˆåŠŸ
        if (languageCode != "und") {
            Log.i("Language", "Language: $languageCode")
        } else {
            Log.i("Language", "Can't identify language")
        }
    }
    .addOnFailureListener { e ->
        // è¯†åˆ«å¤±è´¥
        e.printStackTrace()
    }
```

### ä½¿ç”¨ML Kitè¿›è¡Œæ™ºèƒ½å›å¤å»ºè®®

```kotlin
// åˆ›å»ºæ™ºèƒ½å›å¤å»ºè®®å™¨
val smartReply = SmartReply.getClient()

// å‡†å¤‡å¯¹è¯å†å²
val conversation = mutableListOf<SmartReplySuggestion>()
conversation.add(SmartReplySuggestion.Builder()
    .setText("Hello!")
    .setScore(0.9f)
    .setModelId("model1")
    .build())

// è·å–æ™ºèƒ½å›å¤å»ºè®®
smartReply.suggestReplies(conversation)
    .addOnSuccessListener { suggestions ->
        // è·å–å»ºè®®æˆåŠŸ
        for (suggestion in suggestions) {
            Log.i("SmartReply", "Suggestion: ${suggestion.text}")
        }
    }
    .addOnFailureListener { e ->
        // è·å–å»ºè®®å¤±è´¥
        e.printStackTrace()
    }
```

## å®ç°æ¨èç³»ç»Ÿ

æ¨èç³»ç»Ÿæ˜¯AIåœ¨ç§»åŠ¨åº”ç”¨ä¸­çš„å¦ä¸€ä¸ªé‡è¦åº”ç”¨ï¼Œå¯ä»¥ä¸ºç”¨æˆ·æä¾›ä¸ªæ€§åŒ–çš„å†…å®¹æ¨èã€‚

### åŸºäºå†…å®¹çš„æ¨è

```kotlin
class ContentBasedRecommender {
    private val itemFeatures: Map<String, FloatArray>
    private val userPreferences: MutableMap<String, FloatArray> = mutableMapOf()
    
    init {
        // åŠ è½½ç‰©å“ç‰¹å¾
        itemFeatures = loadItemFeatures()
    }
    
    fun recommendItems(userId: String, itemCount: Int = 10): List<String> {
        // è·å–ç”¨æˆ·åå¥½
        val preferences = userPreferences[userId] ?: calculateUserPreferences(userId)
        
        // è®¡ç®—ç›¸ä¼¼åº¦
        val similarities = mutableMapOf<String, Float>()
        for ((itemId, features) in itemFeatures) {
            val similarity = cosineSimilarity(preferences, features)
            similarities[itemId] = similarity
        }
        
        // è¿”å›æœ€ç›¸ä¼¼çš„ç‰©å“
        return similarities.entries
            .sortedByDescending { it.value }
            .take(itemCount)
            .map { it.key }
    }
    
    private fun calculateUserPreferences(userId: String): FloatArray {
        // è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ ¹æ®ç”¨æˆ·å†å²è¡Œä¸ºè®¡ç®—
        val preferences = FloatArray(100) // å‡è®¾ç‰¹å¾ç»´åº¦ä¸º100
        // å¡«å……ç”¨æˆ·åå¥½...
        
        userPreferences[userId] = preferences
        return preferences
    }
    
    private fun cosineSimilarity(vectorA: FloatArray, vectorB: FloatArray): Float {
        var dotProduct = 0.0f
        var normA = 0.0f
        var normB = 0.0f
        
        for (i in vectorA.indices) {
            dotProduct += vectorA[i] * vectorB[i]
            normA += vectorA[i] * vectorA[i]
            normB += vectorB[i] * vectorB[i]
        }
        
        return dotProduct / (sqrt(normA) * sqrt(normB))
    }
}
```

## AIæ¨¡å‹ä¼˜åŒ–ä¸éƒ¨ç½²

åœ¨Androidåº”ç”¨ä¸­é›†æˆAIæ¨¡å‹æ—¶ï¼Œæ€§èƒ½ä¼˜åŒ–å’Œé«˜æ•ˆéƒ¨ç½²è‡³å…³é‡è¦ã€‚

### æ¨¡å‹é‡åŒ–

æ¨¡å‹é‡åŒ–å¯ä»¥å‡å°‘æ¨¡å‹å¤§å°å¹¶æé«˜æ¨ç†é€Ÿåº¦ï¼š

```kotlin
// ä½¿ç”¨TensorFlow Liteæ”¯æŒåº“è¿›è¡Œé‡åŒ–
val quantizedModel = quantizeModel(originalModel)

// ä½¿ç”¨é‡åŒ–åçš„æ¨¡å‹
val interpreter = Interpreter(quantizedModel)
```

### æ¨¡å‹å‹ç¼©

å¯¹äºå¤§å‹æ¨¡å‹ï¼Œå¯ä»¥ä½¿ç”¨æ¨¡å‹å‹ç¼©æŠ€æœ¯ï¼š

```kotlin
// ä½¿ç”¨TensorFlow Liteæ¨¡å‹ä¼˜åŒ–å·¥å…·
val optimizedModel = optimizeModel(model, OptimizeOptions.Builder()
    .setOptimizationFlags(OptimizeOptions.OPTIMIZE_FOR_LATENCY)
    .build())
```

### ä½¿ç”¨è®¾å¤‡ç«¯æ¨ç†

å¯¹äºæ•æ„Ÿæ•°æ®ï¼Œåº”å°½é‡ä½¿ç”¨è®¾å¤‡ç«¯æ¨ç†ï¼š

```kotlin
// ç¡®ä¿æ¨¡å‹åœ¨è®¾å¤‡ä¸Šè¿è¡Œ
val options = Interpreter.Options()
options.setUseNNAPI(true) // ä½¿ç”¨NN APIåŠ é€Ÿ
options.setNumThreads(4) // ä½¿ç”¨4ä¸ªçº¿ç¨‹

val interpreter = Interpreter(model, options)
```

## AIåº”ç”¨æ€§èƒ½ä¼˜åŒ–

ä¸ºäº†æä¾›æµç•…çš„ç”¨æˆ·ä½“éªŒï¼Œéœ€è¦å¯¹AIåº”ç”¨è¿›è¡Œæ€§èƒ½ä¼˜åŒ–ã€‚

### å¼‚æ­¥å¤„ç†

```kotlin
// ä½¿ç”¨åç¨‹è¿›è¡Œå¼‚æ­¥å¤„ç†
viewModelScope.launch(Dispatchers.IO) {
    val result = model.process(inputData)
    withContext(Dispatchers.Main) {
        // æ›´æ–°UI
        updateUI(result)
    }
}
```

### æ‰¹å¤„ç†

```kotlin
// æ‰¹é‡å¤„ç†å¤šä¸ªè¾“å…¥
fun batchProcess(inputs: List<InputData>): List<Result> {
    return inputs.map { input ->
        // ä½¿ç”¨åç¨‹å¹¶è¡Œå¤„ç†
        async(Dispatchers.IO) {
            model.process(input)
        }
    }.awaitAll()
}
```

### èµ„æºç®¡ç†

```kotlin
class AIResourceManager {
    private var model: Model? = null
    
    fun getModel(): Model {
        if (model == null) {
            model = Model.newInstance(context)
        }
        return model!!
    }
    
    fun release() {
        model?.close()
        model = null
    }
}
```

## AIåº”ç”¨éšç§ä¸å®‰å…¨

åœ¨å¤„ç†ç”¨æˆ·æ•°æ®æ—¶ï¼Œéšç§å’Œå®‰å…¨è‡³å…³é‡è¦ã€‚

### æœ¬åœ°å¤„ç†æ•æ„Ÿæ•°æ®

```kotlin
// ä½¿ç”¨æœ¬åœ°æ¨¡å‹å¤„ç†æ•æ„Ÿæ•°æ®ï¼Œé¿å…æ•°æ®ä¸Šä¼ åˆ°æœåŠ¡å™¨
class PrivacyAwareModel {
    private val model: Model
    
    init {
        // åŠ è½½æœ¬åœ°æ¨¡å‹
        model = Model.newInstance(context)
    }
    
    fun processSensitiveData(data: SensitiveData): Result {
        // åœ¨è®¾å¤‡ä¸Šå¤„ç†æ•°æ®
        return model.predict(data)
    }
}
```

### å®‰å…¨å­˜å‚¨æ¨¡å‹

```kotlin
class SecureModelStorage {
    private val cipher: Cipher = Cipher.getInstance("AES/GCM/NoPadding")
    private val secretKey: SecretKey = getOrCreateSecretKey()
    
    fun saveModel(modelName: String, modelData: ByteArray) {
        // åŠ å¯†æ¨¡å‹æ•°æ®
        cipher.init(Cipher.ENCRYPT_MODE, secretKey)
        val iv = cipher.iv
        val encryptedData = cipher.doFinal(modelData)
        
        // ä¿å­˜åŠ å¯†åçš„æ•°æ®å’ŒIV
        val file = File(context.filesDir, "$modelName.encrypted")
        val outputStream = FileOutputStream(file)
        outputStream.write(iv)
        outputStream.write(encryptedData)
        outputStream.close()
    }
    
    fun loadModel(modelName: String): ByteArray {
        // è¯»å–åŠ å¯†åçš„æ•°æ®å’ŒIV
        val file = File(context.filesDir, "$modelName.encrypted")
        val inputStream = FileInputStream(file)
        val iv = ByteArray(12) // GCMæ¨èIVé•¿åº¦ä¸º12å­—èŠ‚
        inputStream.read(iv)
        val encryptedData = inputStream.readBytes()
        inputStream.close()
        
        // è§£å¯†æ¨¡å‹æ•°æ®
        cipher.init(Cipher.DECRYPT_MODE, secretKey, GCMParameterSpec(128, iv))
        return cipher.doFinal(encryptedData)
    }
    
    private fun getOrCreateSecretKey(): SecretKey {
        // å°è¯•ä»å¯†é’¥åº“è·å–å¯†é’¥
        val keyAlias = "ai_model_key"
        
        try {
            val keyStore = KeyStore.getInstance("AndroidKeyStore")
            keyStore.load(null)
            
            if (keyStore.containsAlias(keyAlias)) {
                return keyStore.getKey(keyAlias, null) as SecretKey
            }
        } catch (e: Exception) {
            e.printStackTrace()
        }
        
        // åˆ›å»ºæ–°å¯†é’¥
        val keyGenerator = KeyGenerator.getInstance(
            KeyProperties.KEY_ALGORITHM_AES, "AndroidKeyStore"
        )
        keyGenerator.init(
            KeyGenParameterSpec.Builder(
                keyAlias,
                KeyProperties.PURPOSE_ENCRYPT or KeyProperties.PURPOSE_DECRYPT
            )
            .setBlockModes(KeyProperties.BLOCK_MODE_GCM)
            .setEncryptionPaddings(KeyProperties.ENCRYPTION_PADDING_NONE)
            .setRandomizedEncryptionRequired(false)
            .build()
        )
        
        return keyGenerator.generateKey()
    }
}
```

## ç»“è¯­

AIå’Œæœºå™¨å­¦ä¹ æŠ€æœ¯æ­£åœ¨æ”¹å˜æˆ‘ä»¬å¼€å‘Androidåº”ç”¨çš„æ–¹å¼ã€‚é€šè¿‡æœ¬æ–‡ä»‹ç»çš„æŠ€æœ¯å’Œæ–¹æ³•ï¼Œä½ å¯ä»¥å°†AIåŠŸèƒ½é›†æˆåˆ°è‡ªå·±çš„Androidåº”ç”¨ä¸­ï¼Œä¸ºç”¨æˆ·æä¾›æ›´æ™ºèƒ½ã€æ›´ä¸ªæ€§åŒ–çš„ä½“éªŒã€‚

ä»ML Kitçš„ç®€å•é›†æˆåˆ°è‡ªå®šä¹‰æ¨¡å‹çš„å¤æ‚åº”ç”¨ï¼Œä»è®¡ç®—æœºè§†è§‰åˆ°è‡ªç„¶è¯­è¨€å¤„ç†ï¼Œä»æ¨èç³»ç»Ÿåˆ°æ€§èƒ½ä¼˜åŒ–ï¼Œæˆ‘ä»¬æ¶µç›–äº†Androidåº”ç”¨AIå¼€å‘çš„å„ä¸ªæ–¹é¢ã€‚

éšç€æŠ€æœ¯çš„ä¸æ–­å‘å±•ï¼ŒAIåœ¨ç§»åŠ¨åº”ç”¨ä¸­çš„åº”ç”¨å°†è¶Šæ¥è¶Šå¹¿æ³›ã€‚å¸Œæœ›æœ¬æ–‡èƒ½å¤Ÿå¸®åŠ©ä½ åœ¨è¿™ä¸ªå……æ»¡æœºé‡çš„é¢†åŸŸä¸­æ‰¾åˆ°è‡ªå·±çš„ä½ç½®ï¼Œåˆ›é€ å‡ºçœŸæ­£æ™ºèƒ½çš„Androidåº”ç”¨ã€‚ğŸš€

> AIä¸æ˜¯é­”æ³•ï¼Œä½†å®ƒèƒ½è®©æˆ‘ä»¬çš„åº”ç”¨å˜å¾—æ›´æ™ºèƒ½ã€‚ä½œä¸ºå¼€å‘è€…ï¼Œæˆ‘ä»¬çš„è´£ä»»æ˜¯ç¡®ä¿è¿™äº›æ™ºèƒ½åŠŸèƒ½èƒ½å¤ŸçœŸæ­£ä¸ºç”¨æˆ·å¸¦æ¥ä»·å€¼ï¼Œè€Œä¸æ˜¯ç®€å•åœ°ç‚«æŠ€ã€‚è®©æˆ‘ä»¬ä¸€èµ·æ‰“é€ æ—¢æ™ºèƒ½åˆäººæ€§åŒ–çš„Androidåº”ç”¨å§ï¼