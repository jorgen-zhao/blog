---
title: 监控设备接入
date: 2023-02-05 09:24:01
permalink: /pages/a3a632/
categories:
  - 开发日志
tags:
  - 
author: 
  name: Jorgen
  link: https://github.com/jorgen-zhao
---

::: tip 说明
对接海康摄像头的一些记录
:::

## 海康摄像头的对接方式

## 设备网络SDK
- 下载地址：https://open.hikvision.com/download/5cda567cf47ae80dd41a54b3?type=10)
> 设备网络SDK是基于设备私有网络通信协议开发的，为海康威视各类硬件产品服务的配套模块，用于远程访问和控制设备的软件二次开发，内含SDK动态库、开发文档 及Demo示例（包括Java、c#、Python等）。

本项目主要是使用Java对接设备网络SDK方式。

优点: 有现成的DEMO,跟着txt说明，很快就能对接上海康的网络摄像头。实现诸如:实时监控,录像回放等功能。

缺点: 
- 使用JNI这种调用方式。存在潜在的性能风险。
- 语音对讲库：音频编解码目前仅Win32版本SDK支持。Linux系统下无语音对讲、语音广播、音频编解码功能，仅支持语音转发接口。

## WEB开发包
下载地址: https://open.hikvision.com/download/5cda567cf47ae80dd41a54b3?type=10&id=4c945d18fa5f49638ce517ec32e24e24
- WEB3.2无插件版本开发包，支持高版本谷歌、火狐浏览器，同时需要设备支持Websocket取流。无插件版本需要使用nginx代理服务器。
- 支持Win32&Win64，支持的浏览器有：IE6~IE11、Chrome8~ Chrome42、Firefox3.5~ Firefox52（32位，64位是到Firefox40）、Safari5.0.2+，需要浏览器支持NPAPI。

优点: 使用浏览器就能快速搭建器调试网络摄像头的模块，适合用来演示等场景吧

缺点: 感觉功能有些佛学。我在本地调试的时候，不可语音对讲、只能单画面;会有延迟，失败的几率很高；只能提供IE和旧版chrome浏览器的解码插件。而且还需要设备支持ws。这个方便是方便，不过要求也很高。个人不推荐使用。

## ISUP开发包
下载地址：https://open.hikvision.com/download/5cda567cf47ae80dd41a54b3?type=10&id=18e1e779efed4593bfceba6703d7f6a8
> 基于私有ISUP协议开发的SDK，动态库形式提供，适用于“硬件设备没有固定IP地址”的网络环境，是硬件设备和平台服务器交互的通信接口，支持AI智能前后端产品、通用前后端产品、门禁产品、交通产品、报警产品、热成像产品等多种网络硬件设备。

这个主要对接海康自家的私有协议EHone。目前Java版本，我还没有看到开源的版本。个人感觉应该与Java SDK对接这种方式类似吧。[找到一篇博客](https://blog.csdn.net/x_y_csdn/article/details/109691014)，希望能有所帮助吧。

- Github上有个[GO语言实现的EHome对接版本](https://github.com/tsingeye/FreeEhome)。目前已经实现的功能包括：实时预览， 报警监听， 设备控制，云台控制。系统基于beego框架开发，提供RESTful接口。CMS信令由海康ehome协议而来，基于UDP+XML进行通信。SMS直接使用[ZLMediaKit](https://github.com/xia-chu/ZLMediaKit)

这个协议呢，主要是使用物联网卡。这种设备肯定价格更贵咯。不过，能适应一些网线拉不到的地方。各有利弊吧

## 萤石云
- 地址：https://open.ys7.com/console/device.html

个人觉得最简单的对接方式哈😂。注册一个账号，然后将设备的设备号与校验码注册上去。免费账号可以接入10台设备。接入之后，就能看到设备，点击可看直播，回放。控制等操作了。如果想集成，也提供了[JS版本的接口与demo](https://open.ys7.com/doc/zh/uikit/uikit_javascript.html)。可供你快速搭建一个拥有监控演示的系统。而且无论移动端还是PC端都能很好的使用。体验不错。

缺点: 高度集成化了。如果设备多，或者想定制化的话，要么花钱走企业服务。要么就多注册几个账号，来注册使用。

## 国标
> GB28181协议指的是国家标准`GB/T 28181—2016`《公共安全视频监控联网系统信息传输、交换、控制技术要求》。

1. 该标准规定了公共安全视频监控联网系统的互联结构， 传输、交换、控制的基本要求和安全性要求， 以及控制、传输流程和协议接口等技术要求，是视频监控领域的国家标准。GB28181协议信令层面使用的是`SIP（Session Initiation Protocol）协议`。
2. 流媒体传输层面使用的是`实时传输协议（Real-time Transport Protocol，RTP）协议`
3. 因此可以理解为GB28181是在国际通用标准的基础之上进行了私有化定制以满足视频监控联网系统互联传输的标准化需求。

优点：不用考虑之后对接的摄像头不是海康不能对接的情况。基本国内的摄像头都会支持国标。

缺点：国标的协议繁杂，实现复杂。

Java版本国标协议开源项目推荐[wvp-GB28181-pro](https://github.com/648540858/wvp-GB28181-pro)。基于GB28181-2016标准实现的网络视频平台，支持NAT穿透，支持海康、大华、宇视等品牌的IPC、NVR、DVR接入。支持国标级联，支持rtsp/rtmp等视频流转发到国标平台，支持rtsp/rtmp等推流转发到国标平台。

也非常容易上手，根据项目的说明，很快就能搭建起一个监控系统。而且如果有定制需求，可以自己拿到源码更改。

## 

## 硬解码&软解码

**软解码：**指利用`CPU`的计算能力来解码，通常如果CPU的能力不是很强的时候，一则解码速度会比较慢，二则手机可能出现发热现象。但是，由于使用统一的算法，兼容性会很好。

**硬解码：**指的是利用手机上专门的解码芯片来加速解码。通常硬解码的解码速度会快很多，但是由于硬解码由各个厂家实现，质量参差不齐，非常容易出现兼容性问题。

## **音视频容器**

细心的读者可能已经发现，前面我们介绍的各种音视频的编码格式，没有一种是我们平时使用到的视频格式，比如：mp4、rmvb、avi、mkv、mov...

没错，这些我们熟悉的视频格式，其实是包裹了音视频编码数据的容器，用来把以特定编码标准编码的视频流和音频流混在一起，成为一个文件。

例如：mp4支持H264、H265等视频编码和AAC、MP3等音频编码。

> mp4是目前最流行的视频格式，在移动端，一般将视频封装为mp4格式。

## 视频帧

帧，是视频的一个基本概念，表示一张画面，就是一帧。一个视频就是由许许多多帧组成的。

视频是由一帧一帧画面构成的，但是在视频的数据中，并不是真正按照一帧一帧原始数据保存下来的（如果这样，压缩编码就没有意义了）。

H264会根据一段时间内，画面的变化情况，选取一帧画面作为完整编码，下一帧只记录与上一帧完整数据的差别，是一个动态压缩的过程。

在H264中，三种类型的帧数据分别为

**I帧**：帧内编码帧。就是一个完整帧。

**P帧**：前向预测编码帧。是一个非完整帧，通过参考前面的I帧或P帧生成。

**B帧**：双向预测内插编码帧。参考前后图像帧编码生成。B帧依赖其前最近的一个I帧或P帧及其后最近的一个P帧。

- **图像组：GOP和关键帧：IDR**

全称：Group of picture。指一组变化不大的视频帧。

GOP的第一帧成为关键帧：IDR

IDR都是I帧，可以防止一帧解码出错，导致后面所有帧解码出错的问题。当解码器在解码到IDR的时候，会将之前的参考帧清空，重新开始一个新的序列，这样，即便前面一帧解码出现重大错误，也不会蔓延到后面的数据中。

> 注：关键帧都是I帧，但是I帧不一定是关键帧
> 
- **DTS与PTS**

DTS全称：Decoding Time Stamp。标示读入内存中数据流在什么时候开始送入解码器中进行解码。也就是解码顺序的时间戳。

PTS全称：Presentation Time Stamp。用于标示解码后的视频帧什么时候被显示出来。

> 在没有B帧的情况下，DTS和PTS的输出顺序是一样的，一旦存在B帧，PTS和DTS则会不同。
> 

### **帧率**

帧率，即单位时间内帧的数量，单位为：帧/秒 或fps（frames per second）。如动画书中，一秒内包含多少张图片，图片越多，画面越顺滑，过渡越自然。

帧率的一般以下几个典型值：

24/25 fps：1秒 24/25 帧，一般的电影帧率。

30/60 fps：1秒 30/60 帧，游戏的帧率，30帧可以接受，60帧会感觉更加流畅逼真。

85 fps以上人眼基本无法察觉出来了，所以更高的帧率在视频里没有太大意义。

### **视频编码格式**

视频编码格式有很多，比如H26x系列和MPEG系列的编码，这些编码格式都是为了适应时代发展而出现的。

其中，H26x（1/2/3/4/5）系列由ITU（International Telecommunication Union）国际电传视讯联盟主导

MPEG（1/2/3/4）系列由MPEG（Moving Picture Experts Group, ISO旗下的组织）主导。

当然，他们也有联合制定的编码标准，那就是现在主流的编码格式H264，当然还有下一代更先进的压缩编码标准H265。

## 音频

音频数据的承载方式最常用的是**脉冲编码调制**，即**PCM。**

根据奈奎斯特采样定理：为了不失真地恢复模拟信号，采样频率应该不小于模拟信号频谱中最高频率的2倍。

根据以上分析，PCM的采集步骤分为以下步骤：

> 模拟信号 → **采样 → 量化 → 编码→ 数字信号**
> 

### **声道数**

声道数，是指支持能**不同发声**（注意是不同声音）的音响的个数。

- 单声道：1个声道
- 双声道：2个声道
- 立体声道：默认为2个声道
- 立体声道（4声道）：4个声道

### **码率**

码率，是指一个数据流中每秒钟能通过的信息量，单位bps（bit per second）

- 码率 = 采样率 * 采样位数 * 声道数

## 编码

我们知道，原始的媒体文件的数据量都是十分庞大的，而为了便于传输和存储，我们通常会编码来对媒体文件进行压缩，这里就涉及到了`编码格式`的概念。
我们常见的视频编码格式有 H.264、MPEG-4、MPEG-2，VC-1 等，而常见的音频编解码格式有 AAC，MP3，AC-3 等。

## **为什么要编码**

这里的编码和上面音频中提到的编码不是同个概念，而是指**压缩编码**。

我们知道，在计算机的世界中，一切都是0和1组成的，音频和视频数据也不例外。由于音视频的数据量庞大，如果按照裸流数据存储的话，那将需要耗费非常大的存储空间，也不利于传送。而音视频中，其实包含了大量0和1的重复数据，因此可以通过一定的算法来压缩这些0和1的数据。

特别在视频中，由于画面是逐渐过渡的，因此整个视频中，包含了大量画面/像素的重复，这正好提供了非常大的压缩空间。

因此，编码可以大大减小音视频数据的大小，让音视频更容易存储和传送。

## 媒体封装格式

一个视频内除了包含编码压缩后视频数据之外，还能够包含音频、字幕等数据，把这些数据都包装到一个文件容器内，就是容器封装的过程。

我们常用的封装格式有： MP4，MOV，TS，FLV，MKV 等。