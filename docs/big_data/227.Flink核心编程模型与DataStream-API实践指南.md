---
title: Flinkæ ¸å¿ƒç¼–ç¨‹æ¨¡å‹ä¸DataStream APIå®è·µæŒ‡å—
date: 2023-11-15 14:30:00
categories: 
  - big_data
tags:
  - Flink
  - DataStream API
  - ç¼–ç¨‹æ¨¡å‹
  - æµå¤„ç†
author: 
  name: Jorgen
  link: https://github.com/jorgen-zhao
---

## å‰è¨€

åœ¨æ·±å…¥ç ”ç©¶äº†Flinkçš„æ¶æ„åŸç†å’Œé…ç½®ç®¡ç†åï¼Œæˆ‘å‘ç°è®¸å¤šå¼€å‘è€…è™½ç„¶ç†è§£äº†åˆ†å¸ƒå¼å¤„ç†çš„åº•å±‚é€»è¾‘ï¼Œå´åœ¨å®é™…ç¼–ç æ—¶å¸¸å¸¸æ„Ÿåˆ°å›°æƒ‘ã€‚ğŸ¤” Flinkçš„ç¼–ç¨‹æ¨¡å‹ç©¶ç«Ÿå¦‚ä½•å°†åˆ†å¸ƒå¼æŠ½è±¡è½¬åŒ–ä¸ºå¯æ“ä½œçš„ä»£ç ï¼Ÿä»Šå¤©æˆ‘ä»¬å°±æ¥æ­å¼€DataStream APIçš„ç¥ç§˜é¢çº±ï¼Œé€šè¿‡å®é™…æ¡ˆä¾‹æŒæ¡æµå¤„ç†ç¼–ç¨‹çš„æ ¸å¿ƒæŠ€å·§ã€‚

> "ä»£ç æ˜¯å·¥ç¨‹å¸ˆçš„è¯­è¨€ï¼Œè€ŒAPIåˆ™æ˜¯è¿™é—¨è¯­è¨€çš„è¯­æ³•ä¹¦" â€”â€” Jorgen

## Flinkç¼–ç¨‹æ¨¡å‹æ ¸å¿ƒæ¦‚å¿µ

::: theorem
Flinkçš„æ ¸å¿ƒç¼–ç¨‹æ¨¡å‹å»ºç«‹åœ¨"æ•°æ®æµ"å’Œ"è½¬æ¢ç®—å­"ä¹‹ä¸Šï¼Œé€šè¿‡æœ‰å‘å›¾(DAG)æè¿°è®¡ç®—é€»è¾‘ï¼Œæœ€ç»ˆç”±åˆ†å¸ƒå¼æ‰§è¡Œå¼•æ“è°ƒåº¦è¿è¡Œã€‚
:::

### 1. æ•°æ®æµæŠ½è±¡

Flinkå°†æ•°æ®è§†ä¸ºæŒç»­æµåŠ¨çš„äº‹ä»¶æµï¼Œç”¨`DataStream` APIè¡¨ç¤ºï¼š

```java
// åˆ›å»ºæ•°æ®æµç¯å¢ƒ
StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

// ä»Kafkaæ¶ˆè´¹æ•°æ®
DataStream<String> stream = env
    .addSource(new FlinkKafkaConsumer<>("topic", new SimpleStringSchema(), properties));
```

### 2. ç®—å­ç±»å‹

Flinkæä¾›ä¸‰ç±»æ ¸å¿ƒç®—å­ï¼š

| ç®—å­ç±»å‹ | åŠŸèƒ½ | ç¤ºä¾‹ |
|---------|------|------|
| **è½¬æ¢ç®—å­** | æ•°æ®å¤„ç† | `map()`, `filter()`, `keyBy()` |
| **è¿æ¥ç®—å­** | å¤šæµåˆå¹¶ | `connect()`, `union()` |
| **èšåˆç®—å­** | æ•°æ®æ±‡æ€» | `reduce()`, `sum()`, `window()` |

## DataStream APIå®æˆ˜æŒ‡å—

### ğŸ— åŸºç¡€è½¬æ¢æ“ä½œ

```java
DataStream<Event> events = env.addSource(new EventSource());

// è½¬æ¢ç¤ºä¾‹ï¼šè¿‡æ»¤+æ˜ å°„
DataStream<String> result = events
    .filter(event -> event.type.equals("click"))  // è¿‡æ»¤ç‚¹å‡»äº‹ä»¶
    .map(event -> event.user + " clicked");       // æå–ç”¨æˆ·ä¿¡æ¯
```

### ğŸ“¡ çŠ¶æ€ç®¡ç†å®è·µ

```java
DataStream<Tuple2<String, Integer>> counts = events
    .keyBy(event -> event.userId)                // æŒ‰ç”¨æˆ·åˆ†ç»„
    .flatMap(new StatefulCounter());              // å¸¦çŠ¶æ€çš„è®¡æ•°å™¨

public static class StatefulCounter extends RichFlatMapFunction<Event, Tuple2<String, Integer>> {
    private transient ValueState<Integer> countState;
    
    @Override
    public void open(Configuration parameters) {
        ValueStateDescriptor<Integer> descriptor = 
            new ValueStateDescriptor<>("count", Integer.class);
        countState = getRuntimeContext().getState(descriptor);
    }
    
    @Override
    public void flatMap(Event event, Collector<Tuple2<String, Integer>> out) {
        Integer currentCount = countState.value();
        currentCount = currentCount == null ? 0 : currentCount + 1;
        countState.update(currentCount);
        out.collect(new Tuple2<>(event.userId, currentCount));
    }
}
```

### ğŸ’¡ çª—å£è®¡ç®—è¿›é˜¶

```java
// æ—¶é—´çª—å£ç¤ºä¾‹
DataStream<Tuple2<String, Long>> windowedCounts = events
    .keyBy(event -> event.category)
    .window(TumblingEventTimeWindows.of(Time.seconds(5)))  // 5ç§’æ»šåŠ¨çª—å£
    .aggregate(new CountAggregator());

// ä¼šè¯çª—å£ç¤ºä¾‹
DataStream<Tuple2<String, Long>> sessionCounts = events
    .keyBy(event -> event.userId)
    .window(EventTimeSessionWindows.withGap(Time.minutes(5)))  // 5åˆ†é’Ÿé—´éš”
    .process(new SessionProcessFunction());
```

## å¸¸è§é™·é˜±ä¸è§£å†³æ–¹æ¡ˆ

### ğŸš« è¯¯ç”¨1ï¼šæ— çŠ¶æ€æ“ä½œå¯¼è‡´æ•°æ®ä¸¢å¤±

```java
// é”™è¯¯ç¤ºä¾‹ï¼šæ— çŠ¶æ€è®¡æ•°
DataStream<Tuple2<String, Integer>> badCounts = events
    .map(event -> new Tuple2<>(event.userId, 1))
    .keyBy(0)
    .sum(1); // æ— æ³•å¤„ç†è¿Ÿåˆ°æ•°æ®
```

**è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨`allowedLateness`å’Œ`sideOutputLateData`ï¼š

```java
DataStream<Tuple2<String, Long>> correctCounts = events
    .keyBy(event -> event.userId)
    .window(TumblingEventTimeWindows.of(Time.minutes(1)))
    .allowedLateness(Time.seconds(30))
    .sideOutputLateData(new OutputTag<Event>("late-events") {})
    .aggregate(new CountAggregator());
```

### ğŸš« è¯¯ç”¨2ï¼šèƒŒå‹å¤„ç†ä¸å½“

```java
// é”™è¯¯ç¤ºä¾‹ï¼šæ— é™åˆ¶çš„å¼‚æ­¥IO
DataStream<Result> results = events
    .map(event -> {
        Future<Result> future = httpClient.sendAsync(event); // æ— é™å¼‚æ­¥è°ƒç”¨
        return future.get(); // é˜»å¡ç­‰å¾…ï¼Œå¯èƒ½å¯¼è‡´èƒŒå‹
    });
```

**è§£å†³æ–¹æ¡ˆ**ï¼šä½¿ç”¨å¼‚æ­¥éé˜»å¡IOï¼š

```java
DataStream<Result> asyncResults = AsyncDataStream.orderedWait(
    events,
    new AsyncRequestFunction<>(), // è‡ªå®šä¹‰å¼‚æ­¥å‡½æ•°
    1000,  // è¶…æ—¶æ—¶é—´
    TimeUnit.MILLISECONDS, 
    100    // å¹¶è¡Œåº¦
);
```

## æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### 1. ç®—å­é“¾ä¼˜åŒ–

```java
// ç¦ç”¨ç®—å­é“¾
env.disableOperatorChaining();

// å¼ºåˆ¶æ–°é“¾èµ·å§‹
DataStream<Tuple2<String, Integer>> chained = events
    .keyBy(0)
    .map(new MyMapper())
    .startNewChain();  // å¼ºåˆ¶æ–°é“¾
```

### 2. çŠ¶æ€åç«¯é€‰æ‹©

```java
// é…ç½®RocksDBçŠ¶æ€åç«¯
env.setStateBackend(new RocksDBStateBackend("hdfs:///flink/checkpoints"));
env.enableCheckpointing(60000); // 1åˆ†é’Ÿæ£€æŸ¥ç‚¹
```

## ç»“è¯­

é€šè¿‡ä»Šå¤©çš„å®è·µï¼Œæˆ‘ä»¬æŒæ¡äº†Flink DataStream APIçš„æ ¸å¿ƒæ“ä½œå’Œæœ€ä½³å®è·µã€‚è®°ä½ï¼Œä¼˜ç§€çš„æµå¤„ç†ä»£ç ä¸ä»…è¦åŠŸèƒ½æ­£ç¡®ï¼Œæ›´è¦è€ƒè™‘å®¹é”™æ€§ã€æ€§èƒ½å’Œå¯ç»´æŠ¤æ€§ã€‚~~åˆ«å†å†™å‡º"çœ‹èµ·æ¥èƒ½è·‘ä½†ä¸€ä¸Šçº¿å°±å´©"çš„ä»£ç å•¦ï¼~~ ğŸ¤£

> "åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œæ²¡æœ‰é“¶å¼¹ï¼Œåªæœ‰æŒç»­ä¼˜åŒ–çš„è€å¿ƒ" â€”â€” Jorgen

**ä¸‹ä¸€æ­¥å»ºè®®**ï¼š
1. å°è¯•å®ç°å¤æ‚äº‹ä»¶å¤„ç†(CEP)åº”ç”¨
2. æ¢ç´¢Flink Table APIä¸SQL
3. ç ”ç©¶Flinkåœ¨å®æ—¶æ•°ä»“ä¸­çš„åº”ç”¨åœºæ™¯

å¸Œæœ›è¿™ç¯‡æŒ‡å—èƒ½å¸®åŠ©ä½ å†™å‡ºæ›´å¥å£®çš„æµå¤„ç†åº”ç”¨ï¼å¦‚æœ‰ç–‘é—®ï¼Œæ¬¢è¿åœ¨è¯„è®ºåŒºäº¤æµ~ ğŸ˜Š