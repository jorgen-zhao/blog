---
title: flink第二弹
date: 2024-01-28 16:22:19
permalink: /pages/726e8d/
categories:
  - Geek Explore
tags:
  - 
author: 
  name: Jorgen
  link: https://github.com/jorgen-zhao
---
## flink 架构
Flink采取master - worker的结构架构，主要包括两个组件
1. Master: Flink作业的主进程，它主要起协调管理的作用
2. TaskManager: 执行计算任务的进程，拥有CPU，内存等资源。Flink需要将计算任务发往多个taskmanger上并行执行任务。

### Flink作业提交的过程
![standalone模式下，作业提交的流程图](/tool/05/201/job-submmit.jpg) 

在一个作业提交前，master与taskmanager需要首先被启动。单机版flink直接使用`bin/start-cluser`命令进行启动，taskmanger启动后向Resource manger注册。这个流程在用户提交jar包前执行。
1. 用户通过SDK编写好的程序，通过client进行提交。现在通常使用Java语言编写，构建逻辑视角数据流图。代码和相关配置文件进行打包编译构建，通过客户端提交到dispatcher，形成一个作业Job.
2. Dispatcher收到这个作业之后，会启动Jobmanager，负责协调本次的工作。
3. Jobmanger向Resource manager申请本次作业所需要的资源。
4. 在整个flink刚启动时，taskmanger已经向resource manger注册，此时，闲置的taskmanager将会反馈给jobmanager。
5. jobmanager将用户作业中的逻辑视图转换为物理执行图，将计算任务分发给多个taskmager。

一个Flink job开始执行！！！

### graph
``` Java
public static void main(String[] args) throws Exception {
  // 检查输入
  final ParameterTool params = ParameterTool.fromArgs(args);
  ...

  // set up the execution environment
  final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

  // get input data
  DataStream<String> text =
      env.socketTextStream(params.get("hostname"), params.getInt("port"), '\n', 0);

  DataStream<Tuple2<String, Integer>> counts =
      // split up the lines in pairs (2-tuples) containing: (word,1)
      text.flatMap(new Tokenizer())
          // group by the tuple field "0" and sum up tuple field "1"
          .keyBy(0)
          .sum(1);
  counts.print();
  
  // execute program
  env.execute("WordCount from SocketTextStream Example");
}
```

![standalone模式下，作业提交的流程图](/tool/05/201/graph.png) 

| 图             | 描述                                                                                                                                                                           | 细节                                                                                                                                                        |
|------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------|
| StreamGraph      | 根据用户通过 Stream API 编写的代码生成的最初的图。用来表示程序的拓扑结构。                                                                                                           | `StreamNode`：用来代表 operator 的类，并具有所有相关的属性，如并发度、入边和出边等。 <br/> `StreamEdge`：表示连接两个StreamNode的边。                                  |
| JobGraph         | StreamGraph经过优化后生成了 JobGraph，提交给 JobManager 的数据结构。主要的优化为，将多个符合条件的节点 chain 在一起作为一个节点，这样可以减少数据在节点之间流动所需要的序列化/反序列化/传输消耗。 | `JobVertex`：经过优化后符合条件的多个`StreamNode`可能会chain在一起生成一个`JobVertex`，即一个`JobVertex`包含一个或多个operator，`JobVertex`的输入是`JobEdge`，输出是`IntermediateDataSet`。 <br/> `IntermediateDataSet`：表示`JobVertex`的输出，即经过operator处理产生的数据集。producer是`JobVertex`，consumer是`JobEdge`。 <br/> `JobEdge`：代表了job graph中的一条数据传输通道。source 是 `IntermediateDataSet`，target 是 JobVertex。即数据通过JobEdge由IntermediateDataSet传递给目标JobVertex。  |
| ExecutionGraph   | JobManager 根据 JobGraph 生成ExecutionGraph。ExecutionGraph是JobGraph的并行化版本，是调度层最核心的数据结构。                                                                   | `ExecutionJobVertex`：和JobGraph中的JobVertex一一对应。每一个ExecutionJobVertex都有和并发度一样多的 ExecutionVertex。<br/> `ExecutionVertex`：表示ExecutionJobVertex的其中一个并发子任务，输入是ExecutionEdge，输出是IntermediateResultPartition。 <br/> `IntermediateResult`：和JobGraph中的IntermediateDataSet一一对应。一个IntermediateResult包含多个IntermediateResultPartition，其个数等于该operator的并发度。 <br/> `IntermediateResultPartition`：表示ExecutionVertex的一个输出分区，producer是ExecutionVertex，consumer是若干个ExecutionEdge。<br/> `ExecutionEdge`：表示ExecutionVertex的输入，source是IntermediateResultPartition，target是ExecutionVertex。source和target都只能是一个。 <br/>`Execution`：是执行一个 ExecutionVertex 的一次尝试。当发生故障或者数据需要重算的情况下 ExecutionVertex 可能会有多个 ExecutionAttemptID。一个 Execution 通过 ExecutionAttemptID 来唯一标识。JM和TM之间关于 task 的部署和 task status 的更新都是通过 ExecutionAttemptID 来确定消息接受者。 |
| 物理执行图       | JobManager 根据 ExecutionGraph 对 Job 进行调度后，在各个TaskManager 上部署 Task 后形成的“图”，并不是一个具体的数据结构。                                                           | `Task`：Execution被调度后在分配的 TaskManager 中启动对应的 Task。Task 包裹了具有用户执行逻辑的 operator。 <br/>`ResultPartition`：代表由一个Task的生成的数据，和ExecutionGraph中的IntermediateResultPartition一一对应。 <br/>`ResultSubpartition`：是ResultPartition的一个子分区。每个ResultPartition包含多个ResultSubpartition，其数目要由下游消费 Task 数和 DistributionPattern 来决定。 <br/>`InputGate`：代表Task的输入封装，和JobGraph中JobEdge一一对应。每个InputGate消费了一个或多个的ResultPartition。 <br/>`InputChannel`：每个InputGate会包含一个以上的InputChannel，和ExecutionGraph中的ExecutionEdge一一对应，也和ResultSubpartition一对一地相连，即一个InputChannel接收一个ResultSubpartition的输出。 |


### 任务执行 资源划分

## time 

### watermark

### window

## 参考
1. http://wuchong.me/categories/Flink/
2. https://lulaoshi.info/flink/chapter-system-design/dataflow.html